{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbcd3015",
   "metadata": {},
   "source": [
    "READER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5137f1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import regex as re\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import math\n",
    "from azure.storage.blob import BlobServiceClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17494b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reader():\n",
    "    def __init__(self, file_path):\n",
    "        self.__file_path = file_path\n",
    "        self.__files = [ f for f in os.listdir(file_path) if os.path.isfile(os.path.join(file_path,f)) ]\n",
    "        self.dataFrames = []\n",
    "\n",
    "    # Returns a list with all the file names in a specific folder\n",
    "    def listFile(self):\n",
    "        return self.__files\n",
    "\n",
    "    # Returns a list of all the dataframes in the folder from csv files\n",
    "    def DfList(self):\n",
    "        if not self.dataFrames:\n",
    "            for file in self.__files:\n",
    "                if file.endswith(\".csv\"):\n",
    "                    self.dataFrames.append(pd.read_csv(os.path.join(self.__file_path, file)))\n",
    "                else:\n",
    "                    raise ValueError(\"File must be a CSV.\")\n",
    "        return self.dataFrames\n",
    "\n",
    "    # Returns a specific dataframe by index \n",
    "    def getDfByIndex(self, index):\n",
    "        self.DfList()\n",
    "        index -= 1\n",
    "        if index < 0 or index >= len(self.dataFrames):\n",
    "            raise ValueError(\"Index out of range.\")\n",
    "        return self.dataFrames[index]\n",
    "    \n",
    "    # Returns the amount of files in the folder\n",
    "    def getLength(self):\n",
    "        return len(self.__files)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d34619",
   "metadata": {},
   "source": [
    "WRITER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "380d5e4f",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after function definition on line 16 (1836272169.py, line 17)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[3], line 17\u001b[1;36m\u001b[0m\n\u001b[1;33m    self.writeCsv()\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block after function definition on line 16\n"
     ]
    }
   ],
   "source": [
    "class Writer():\n",
    "    def __init__(self, dataFrame, fileName, folder_path):\n",
    "        self.df = dataFrame\n",
    "        self.fn = fileName\n",
    "        self.folder_path = folder_path\n",
    "        self.writeCsv()\n",
    "\n",
    "    # Writes a dataframe to a CSV file\n",
    "    def writeCsv(self):\n",
    "        if not isinstance(self.df, pd.DataFrame):\n",
    "            raise ValueError(\"Dataframe must be a pandas DataFrame\")\n",
    "        \n",
    "        self.df.to_csv(os.path.join(self.folder_path, self.fn + '.csv'), index=False)\n",
    "        return print(\"File saved successfully\")\n",
    "    \n",
    "    def writeAzureBlobAndCsv(self):\n",
    "    self.writeCsv()\n",
    "    \n",
    "    conn_str = \"DefaultEndpointsProtocol=https;AccountName=batchprocessing94;AccountKey=aH9cA5Xwbv+fELTDQPG3BZaM1AvUAK7LQTX5A6PDYMHTw6EqcXlSvzlw5Aqfs7i3XdJSzgQQw3OZ+AStf56OCw==;EndpointSuffix=core.windows.net\"\n",
    "    container_name = \"batchprocessingcontainer\"\n",
    "    blob_name = \"real_time_data.csv\"\n",
    "    file_path = \"output/processed_data.csv\"\n",
    "\n",
    "    blob_service_client = BlobServiceClient.from_connection_string(conn_str)\n",
    "    blob_client = blob_service_client.get_blob_client(container=container_name, blob=blob_name)\n",
    "\n",
    "    with open(file_path, \"rb\") as data:\n",
    "        blob_client.upload_blob(data)\n",
    "        print(\"File uploaded to Azure Blob Storage successfully\")      \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3bf7f49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader('airflow/dags/files/realtime/')\n",
    "# filenames = ['test1', 'test2']\n",
    "\n",
    "# for filename, file in zip(filenames, reader.DfList()):\n",
    "#     Writer(file, filename, 'output')\n",
    "\n",
    "df = reader.getDfByIndex(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c967ce9b",
   "metadata": {},
   "source": [
    "VALIDATOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d73ff09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation passed: No errors found.\n"
     ]
    }
   ],
   "source": [
    "def validate_name(value):\n",
    "    if not isinstance(value, str):\n",
    "        return False\n",
    "\n",
    "    return True\n",
    "\n",
    "def validate_platform(value):\n",
    "    valid_platforms = {\n",
    "        'Wii', 'NES', 'GB', 'DS', 'X360', 'PS3', 'PS2', 'SNES', 'GBA', 'PS4', '3DS', 'N64',\n",
    "        'PS', 'XB', 'PC', '2600', 'PSP', 'XOne', 'WiiU', 'GC', 'GEN', 'DC', 'PSV', 'SAT',\n",
    "        'SCD', 'WS', 'NG', 'TG16', '3DO', 'GG', 'PCFX'\n",
    "    }\n",
    "\n",
    "    if not isinstance(value, str):\n",
    "        return False\n",
    "    value = value.strip()\n",
    "    return value in valid_platforms\n",
    "\n",
    "def validate_yearOfRelease(value):\n",
    "    if not isinstance(value, float):\n",
    "        return False\n",
    "\n",
    "    if value > datetime.now().year:\n",
    "        return False\n",
    "\n",
    "    return True\n",
    "\n",
    "def validate_genre(value):\n",
    "    if not isinstance(value, str):\n",
    "        return False\n",
    "\n",
    "    valid_genres = {\n",
    "        'Action', 'Adventure', 'Fighting', 'Misc', 'Platform', 'Puzzle', 'Racing',\n",
    "        'Role-Playing', 'Shooter', 'Simulation', 'Sports', 'Strategy'\n",
    "    }\n",
    "\n",
    "    value = value.strip()\n",
    "    return value in valid_genres\n",
    "\n",
    "def validate_publisher(value):\n",
    "    if not isinstance(value, str):\n",
    "        return False\n",
    "    \n",
    "    value_correct = value.strip()\n",
    "    if not value_correct:\n",
    "        return False\n",
    "\n",
    "    return True\n",
    "\n",
    "def validate_sales(value):\n",
    "    if not isinstance(value, float):\n",
    "        return False\n",
    "\n",
    "    if value < 0 or value > 100:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def validate_global_sales(value):\n",
    "    if not isinstance(value, float):\n",
    "        return False\n",
    "\n",
    "    return True\n",
    "\n",
    "def validate_scores_counts(value):\n",
    "    if not isinstance(value, float):\n",
    "        return False\n",
    "\n",
    "    if value < 0:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def validate_User_Score(value):\n",
    "    if not isinstance(value, str):\n",
    "        return False\n",
    "    \n",
    "    if value == 'tbd':\n",
    "        return True\n",
    "\n",
    "    try:\n",
    "        value = float(value)\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "    if value < 0 or value > 10:\n",
    "        return False\n",
    "\n",
    "    return True\n",
    "\n",
    "def validate_rating(value):\n",
    "    if not isinstance(value, str):\n",
    "        return False\n",
    "\n",
    "    valid_ratings = {\n",
    "        'E', 'M', 'T', 'E10+', 'K-A', 'AO', 'EC', 'RP'\n",
    "    }\n",
    "\n",
    "    value = value.strip().upper()\n",
    "    return value in valid_ratings\n",
    "\n",
    "\n",
    "def validate_row(row):\n",
    "    errors = []\n",
    "\n",
    "    validations = {\n",
    "        'Name': validate_name,\n",
    "        'Platform': validate_platform,\n",
    "        'Year_of_Release': validate_yearOfRelease,\n",
    "        'Genre': validate_genre,\n",
    "        'Publisher': validate_publisher,\n",
    "        'NA_Sales': validate_sales,\n",
    "        'EU_Sales': validate_sales,\n",
    "        'JP_Sales': validate_sales,\n",
    "        'Other_Sales': validate_sales,\n",
    "        'Global_Sales': validate_global_sales,\n",
    "        'Critic_Score': validate_scores_counts,\n",
    "        'Critic_Count': validate_scores_counts,\n",
    "        'User_Score': validate_User_Score,\n",
    "        'User_Count': validate_scores_counts,\n",
    "        'Developer': validate_name,\n",
    "        'Rating': validate_rating,\n",
    "    }\n",
    "\n",
    "    for column, validator in validations.items():\n",
    "        value = row.get(column)\n",
    "        if pd.isna(value):\n",
    "            continue \n",
    "        if not validator(value):\n",
    "            errors.append(f\"Invalid value in column '{column}': {value}\")\n",
    "\n",
    "    try:\n",
    "        if not pd.isna(row['Global_Sales']):\n",
    "            na = row.get('NA_Sales', 0.0) or 0.0\n",
    "            eu = row.get('EU_Sales', 0.0) or 0.0\n",
    "            jp = row.get('JP_Sales', 0.0) or 0.0\n",
    "            other = row.get('Other_Sales', 0.0) or 0.0\n",
    "            global_sales = row['Global_Sales']\n",
    "\n",
    "            expected_total = na + eu + jp + other\n",
    "\n",
    "            if abs(global_sales - expected_total) > 0.03:\n",
    "                errors.append(\n",
    "                    f\"Global_Sales mismatch: expected ~{expected_total:.2f}, got {global_sales:.2f}\"\n",
    "                )\n",
    "    except Exception as e:\n",
    "        errors.append(f\"Error validating Global_Sales: {str(e)}\")\n",
    "\n",
    "    return errors\n",
    "\n",
    "\n",
    "\n",
    "def validate_dataset(df):\n",
    "    all_errors = {}\n",
    "    for index, row in df.iterrows():\n",
    "        errors = validate_row(row)\n",
    "        if errors:\n",
    "            all_errors[index] = errors\n",
    "    return all_errors\n",
    "\n",
    "validation_errors = validate_dataset(df)\n",
    "\n",
    "\n",
    "if validation_errors:\n",
    "    for row_idx, errors in validation_errors.items():\n",
    "        print(f\"Row {row_idx}:\")\n",
    "        for error in errors:\n",
    "            print(f\"  - {error}\")\n",
    "else:\n",
    "    print(\"Validation passed: No errors found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f5a584",
   "metadata": {},
   "source": [
    "PROCESSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1b0265",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(df):\n",
    "    mandatory_columns = [\n",
    "        'Name', 'Platform', 'Year_of_Release', 'Genre', 'Publisher', 'NA_Sales',\n",
    "        'EU_Sales', 'JP_Sales', 'Other_Sales', 'Global_Sales']\n",
    "    \n",
    "    # Drop rows with missing values in mandatory columns\n",
    "    df = df.dropna(subset=mandatory_columns)\n",
    "\n",
    "    # Remove duplicates based on mandatory columns\n",
    "    df_cleaned = df.drop_duplicates(subset=mandatory_columns, keep='first')\n",
    "\n",
    "    # get the best selling region and the ratio for the best selling region\n",
    "    def get_best_selling_region_and_ratio(row):\n",
    "        # Define sales per region\n",
    "        regions = {\n",
    "            \"North-America\": row[\"NA_Sales\"],\n",
    "            \"Europe\": row[\"EU_Sales\"],\n",
    "            \"Japan\": row[\"JP_Sales\"],\n",
    "            \"Other\": row[\"Other_Sales\"]\n",
    "        }\n",
    "        \n",
    "        best_region = max(regions, key=regions.get)\n",
    "        \n",
    "        best_region_sales = regions[best_region]\n",
    "        \n",
    "        if row[\"Global_Sales\"] != 0:\n",
    "            sales_ratio = best_region_sales / row[\"Global_Sales\"]\n",
    "        else:\n",
    "            sales_ratio = 0  \n",
    "        \n",
    "        return pd.Series([best_region, sales_ratio], index=[\"Best_Selling_Region\", \"Best_Selling_Region_Sales_Ratio\"])\n",
    "\n",
    "    # apply the function to each row to get the best selling region and ratio\n",
    "    df_cleaned[['Best_Selling_Region', 'Best_Selling_Region_Sales_Ratio']] = df_cleaned.apply(get_best_selling_region_and_ratio, axis=1)\n",
    "\n",
    "    # Get the contribution of this game to the total sales of its platform\n",
    "    platform_sales_total = df_cleaned.groupby(\"Platform\")[\"Global_Sales\"].sum()\n",
    "    df_cleaned[\"Platform_Sales_Contribution\"] = df_cleaned.apply(\n",
    "        lambda row: row[\"Global_Sales\"] / platform_sales_total[row[\"Platform\"]] if platform_sales_total[row[\"Platform\"]] != 0 else 0,\n",
    "        axis=1\n",
    "    )\n",
    "    return df_cleaned\n",
    "\n",
    "df_processed = process_data(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "a17a75f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved successfully\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.Writer at 0x20048d33bd0>"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Writer(df_processed, 'processed_real_data', 'output')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
